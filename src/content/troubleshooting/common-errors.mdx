---
title: "Common Errors"
description: "Comprehensive guide to common Xether AI errors and their solutions"
---

import { Callout } from "@/components/ui/Callout";
import { CodeBlock } from "@/components/ui/CodeBlock";

# Common Errors

This guide covers the most common errors you might encounter when using Xether AI, along with their causes and solutions.

## Configuration Errors

### Invalid Pipeline Configuration

**Error**: `Invalid pipeline configuration: missing required field 'source'`

**Cause**: The pipeline YAML file is missing required fields or has invalid syntax.

**Solution**:
```yaml
# Correct pipeline configuration
name: "my-pipeline"  # Required
source:             # Required
  type: "s3"
  bucket: "my-bucket"
  path: "data/"
stages:             # Required
  - type: "clean"
    config: {}
```

**Troubleshooting Steps**:
1. Validate YAML syntax using an online YAML validator
2. Check for required fields: `name`, `source`, `stages`
3. Ensure proper indentation (2 spaces per level)
4. Verify all stage types are supported

### Authentication Errors

**Error**: `Authentication failed: invalid API key`

**Cause**: Invalid or missing API key in configuration.

**Solution**:
```bash
# Set API key as environment variable
export XETHER_API_KEY="your_api_key_here"

# Or in configuration file
xether config set api_key "your_api_key_here"
```

**Troubleshooting Steps**:
1. Verify API key is correct and active
2. Check for extra spaces or special characters
3. Ensure API key has required permissions
4. Test API key with a simple command

## Data Processing Errors

### Schema Mismatch

**Error**: `Schema validation failed: field 'age' type mismatch`

**Cause**: Input data doesn't match expected schema.

**Solution**:
```yaml
# Define explicit schema
stages:
  - type: "validate"
    config:
      schema:
        age: "integer"
        name: "string"
        email: "email"
      strict_mode: false  # Allow type conversion
```

**Troubleshooting Steps**:
1. Check actual data types in source
2. Update schema to match actual data
3. Add type conversion stages if needed
4. Use `strict_mode: false` for flexible validation

### Memory Issues

**Error**: `Out of memory: cannot process dataset`

**Cause**: Dataset too large for available memory.

**Solution**:
```yaml
# Enable streaming processing
stages:
  - type: "ingest"
    config:
      streaming: true
      chunk_size: 10000
      
  - type: "memory_managed"
    config:
      spill_to_disk: true
      memory_limit: "4GB"
```

**Troubleshooting Steps**:
1. Enable streaming for large datasets
2. Reduce chunk size
3. Enable disk spilling
4. Increase available memory resources

## Connection Errors

### Network Timeout

**Error**: `Connection timeout: unable to reach data source`

**Cause**: Network connectivity issues or slow data source.

**Solution**:
```yaml
# Configure timeouts and retries
source:
  type: "s3"
  bucket: "my-bucket"
  config:
    timeout: 300  # 5 minutes
    retries: 3
    retry_delay: 60  # 1 minute
```

**Troubleshooting Steps**:
1. Check network connectivity
2. Increase timeout values
3. Configure retry logic
4. Verify data source accessibility

### Permission Denied

**Error**: `Access denied: insufficient permissions for resource`

**Cause**: Missing or incorrect permissions for data source.

**Solution**:
```bash
# Check AWS credentials (for S3)
aws s3 ls s3://my-bucket/

# Update IAM permissions
aws iam attach-user-policy \
  --user-name my-user \
  --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess
```

**Troubleshooting Steps**:
1. Verify credentials are correctly configured
2. Check IAM permissions for AWS services
3. Ensure bucket/object permissions allow access
4. Test with minimal permissions first

## Pipeline Execution Errors

### Stage Failure

**Error**: `Stage 'transform' failed: error in transformation logic`

**Cause**: Error in specific pipeline stage execution.

**Solution**:
```yaml
# Add error handling
stages:
  - type: "transform"
    config:
      error_handling: "continue"
      log_errors: true
      max_error_rate: 0.05  # 5% error threshold
```

**Troubleshooting Steps**:
1. Check stage logs for detailed error information
2. Validate transformation logic
3. Test with smaller dataset
4. Add error handling and logging

### Dependency Issues

**Error**: `Dependency not found: required stage 'clean' not found`

**Cause**: Pipeline references non-existent stages or dependencies.

**Solution**:
```yaml
# Define all required stages
stages:
  - name: "clean"
    type: "clean"
    config: {}
    
  - name: "transform"
    type: "transform"
    depends_on: ["clean"]  # Explicit dependency
    config: {}
```

**Troubleshooting Steps**:
1. Verify all stage names are unique
2. Check dependency references
3. Ensure stage order is logical
4. Use explicit dependencies when needed

## Data Quality Errors

### High Error Rate

**Error**: `Data quality threshold exceeded: error rate 15% > 5%`

**Cause**: Data quality below acceptable threshold.

**Solution**:
```yaml
# Adjust quality thresholds
stages:
  - type: "validate"
    config:
      quality_threshold: 0.90  # 90% quality
      error_threshold: 0.10    # 10% error rate
      
  - type: "clean"
    config:
      handle_errors: true
      error_correction: "auto"
```

**Troubleshooting Steps**:
1. Analyze specific quality issues
2. Adjust thresholds to realistic values
3. Add data cleaning stages
4. Implement error correction logic

### Missing Values

**Error**: `Missing value threshold exceeded: 25% > 10%`

**Cause**: Too many missing values in dataset.

**Solution**:
```yaml
# Handle missing values
stages:
  - type: "handle_missing"
    config:
      strategy: "impute"
      method: "mean"
      threshold: 0.20  # Allow up to 20% missing
      
  - type: "validate"
    config:
      missing_threshold: 0.20
```

**Troubleshooting Steps**:
1. Identify fields with high missing rates
2. Choose appropriate imputation strategy
3. Adjust missing value thresholds
4. Consider data source improvements

## Performance Errors

### Slow Processing

**Error**: `Performance warning: processing time exceeded SLA`

**Cause**: Pipeline taking too long to complete.

**Solution**:
```yaml
# Optimize performance
stages:
  - type: "parallel"
    config:
      workers: 4
      batch_size: 5000
      
  - type: "cache"
    config:
      enabled: true
      strategy: "memory"
```

**Troubleshooting Steps**:
1. Enable parallel processing
2. Optimize batch sizes
3. Add caching for repeated operations
4. Profile pipeline performance

### Resource Exhaustion

**Error**: `Resource limit exceeded: CPU usage 95%`

**Cause**: Pipeline consuming too many system resources.

**Solution**:
```yaml
# Configure resource limits
resources:
  cpu_limit: "4 cores"
  memory_limit: "8GB"
  disk_limit: "100GB"
  
stages:
  - type: "resource_monitor"
    config:
      check_interval: "30s"
      alert_threshold: 80
```

**Troubleshooting Steps**:
1. Set appropriate resource limits
2. Monitor resource usage
3. Optimize resource-intensive stages
4. Consider scaling up resources

## Integration Errors

### API Errors

**Error**: `API request failed: rate limit exceeded`

**Cause**: Too many API requests in short time.

**Solution**:
```yaml
# Configure rate limiting
source:
  type: "api"
  config:
    rate_limit: 100  # requests per minute
    burst_size: 10
    retry_delay: 60
```

**Troubleshooting Steps**:
1. Implement rate limiting
2. Use exponential backoff for retries
3. Cache API responses when possible
4. Consider batch processing

### Database Errors

**Error**: `Database connection failed: connection timeout`

**Cause**: Database connectivity or performance issues.

**Solution**:
```yaml
# Configure database connection
source:
  type: "database"
  config:
    connection_timeout: 30
    query_timeout: 300
    pool_size: 10
    retry_attempts: 3
```

**Troubleshooting Steps**:
1. Check database connectivity
2. Optimize query performance
3. Configure connection pooling
4. Monitor database performance

## Environment Errors

### Version Compatibility

**Error**: `Version mismatch: client version 2.1.0 incompatible with server 2.0.0`

**Cause**: Client and server versions not compatible.

**Solution**:
```bash
# Update client to match server
pip install --upgrade xether-ai

# Or check compatibility matrix
xether version check
```

**Troubleshooting Steps**:
1. Check version compatibility matrix
2. Update client or server as needed
3. Use compatible API versions
4. Test with supported versions

### Environment Variables

**Error**: `Environment variable not found: XETHER_API_KEY`

**Cause**: Required environment variables not set.

**Solution**:
```bash
# Set environment variables
export XETHER_API_KEY="your_key"
export XETHER_ENVIRONMENT="production"
export XETHER_LOG_LEVEL="info"

# Or use .env file
echo "XETHER_API_KEY=your_key" > .env
```

**Troubleshooting Steps**:
1. List all required environment variables
2. Set variables in shell or .env file
3. Verify variables are loaded correctly
4. Use environment-specific configurations

## Debugging Tips

### Enable Debug Logging

```yaml
# Enable detailed logging
logging:
  level: "debug"
  format: "json"
  output: "file"
  file_path: "/var/log/xether/debug.log"
  
stages:
  - type: "debug"
    config:
      log_inputs: true
      log_outputs: true
      log_intermediate: true
```

### Use Validation Tools

```bash
# Validate pipeline configuration
xether pipeline validate my-pipeline.yaml

# Test with sample data
xether pipeline test --sample-size 100 my-pipeline.yaml

# Dry run without execution
xether pipeline dry-run my-pipeline.yaml
```

### Monitor Pipeline Execution

```bash
# Run with monitoring
xether pipeline run --monitor --verbose my-pipeline.yaml

# Check pipeline status
xether pipeline status --watch

# View detailed logs
xether pipeline logs --tail --level debug
```

## Getting Help

### Support Channels

<Callout type="info">
**Community Support**: Visit our [community forum](https://community.xether.ai) for help from other users
</Callout>

<Callout type="warning">
**Enterprise Support**: Contact [enterprise-support@xether.ai](mailto:enterprise-support@xether.ai) for priority support
</Callout>

### Error Reporting

When reporting errors, include:

1. **Error message**: Full error text
2. **Pipeline configuration**: YAML file (redacted if sensitive)
3. **Environment details**: OS, version, resources
4. **Steps to reproduce**: What you did before the error
5. **Expected behavior**: What should have happened

### Self-Service Resources

- [Documentation](https://docs.xether.ai)
- [API Reference](/docs/api-reference/overview)
- [CLI Reference](/docs/cli/overview)
- [Examples Repository](https://github.com/xether-ai/examples)

## Prevention Strategies

### Proactive Monitoring

```yaml
# Set up monitoring
monitoring:
  alerts:
    - name: "error_rate_spike"
      condition: "error_rate > 0.05"
      action: "notify"
      
    - name: "performance_degradation"
      condition: "processing_time > 300s"
      action: "scale_resources"
```

### Testing Practices

1. **Unit Tests**: Test individual pipeline stages
2. **Integration Tests**: Test complete pipeline workflows
3. **Performance Tests**: Test with realistic data volumes
4. **Error Scenarios**: Test error handling and recovery

### Configuration Management

1. **Version Control**: Store pipeline configs in Git
2. **Environment Separation**: Different configs for dev/staging/prod
3. **Secrets Management**: Use proper secret management
4. **Backup Plans**: Maintain backup configurations

By following these troubleshooting steps and prevention strategies, you can quickly resolve common errors and maintain reliable Xether AI pipelines.
